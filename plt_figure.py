import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.utils.data as Data
from tqdm import tqdm

def list_to_colormap_mine(x_list):
    y = np.zeros((len(x_list), 3))
    for index, item in enumerate(x_list):
        if item == 0:
            y[index] = np.array([255, 0, 0]) / 255.
        if item == 1:
            y[index] = np.array([0, 255, 0]) / 255.
        if item == 2:
            y[index] = np.array([0, 0, 255]) / 255.
        if item == 3:
            y[index] = np.array([255, 255, 0]) / 255.
        if item == 4:
            y[index] = np.array([0, 255, 255]) / 255.
        if item == 5:
            y[index] = np.array([255, 0, 255]) / 255.
        if item == 6:
            y[index] = np.array([192, 192, 192]) / 255.
        if item == 7:
            y[index] = np.array([128, 128, 128]) / 255.
        if item == 8:
            y[index] = np.array([128, 0, 0]) / 255.
        if item == 9:
            y[index] = np.array([128, 128, 0]) / 255.
        if item == 10:
            y[index] = np.array([0, 128, 0]) / 255.
        if item == 11:
            y[index] = np.array([128, 0, 128]) / 255.
        if item == 12:
            y[index] = np.array([0, 128, 128]) / 255.
        if item == 13:
            y[index] = np.array([0, 0, 128]) / 255.
        if item == 14:
            y[index] = np.array([255, 165, 0]) / 255.
        if item == 15:
            y[index] = np.array([255, 215, 0]) / 255.
        if item == 16:
            y[index] = np.array([0, 0, 0]) / 255.
        if item == 17:
            y[index] = np.array([215, 255, 0]) / 255.
        if item == 18:
            y[index] = np.array([0, 255, 215]) / 255.
        if item == -1:
            y[index] = np.array([0, 0, 0]) / 255.
    return y

def classification_map(map, ground_truth, dpi, save_path):
    fig = plt.figure(frameon=False)
    fig.set_size_inches(ground_truth.shape[1] * 2.0 / dpi,
                        ground_truth.shape[0] * 2.0 / dpi)
    ax = plt.Axes(fig, [0., 0., 1., 1.])
    ax.set_axis_off()
    ax.xaxis.set_visible(False)
    ax.yaxis.set_visible(False)
    fig.add_axes(ax)
    ax.imshow(map)
    fig.savefig(save_path, dpi=dpi)
    return 0

def index_assignment(index, row, col, pad_length):
    new_assign = {}
    for counter, value in enumerate(index):
        assign_0 = value // col + pad_length
        assign_1 = value % col + pad_length
        new_assign[counter] = [assign_0, assign_1]
    return new_assign

def select_patch(matrix, pos_row, pos_col, ex_len):
    selected_rows = matrix[range(pos_row-ex_len, pos_row+ex_len+1)]
    selected_patch = selected_rows[:, range(pos_col-ex_len, pos_col+ex_len+1)]
    return selected_patch

def select_small_cubic(data_size, data_indices, whole_data, patch_length, padded_data):
    dimension = whole_data.shape[2]
    small_cubic_data = np.zeros((data_size, patch_length, patch_length, dimension))
    data_assign = index_assignment(data_indices, whole_data.shape[0], whole_data.shape[1], patch_length)
    for i in range(len(data_assign)):
        small_cubic_data[i] = select_patch(padded_data, data_assign[i][0], data_assign[i][1], patch_length//2)
    return small_cubic_data


def generate_iter_all(length, list_temp, whole_data, padded_data, PATCH_LENGTH, batch_size=256):
    gt_all = np.zeros(length)

    all_data = select_small_cubic(length, list_temp, whole_data, PATCH_LENGTH, padded_data)
    INPUT_DIMENSION = whole_data.shape[2]
    all_data.reshape(all_data.shape[0], all_data.shape[1], all_data.shape[2], INPUT_DIMENSION)
    all_tensor_data = torch.from_numpy(all_data).type(torch.FloatTensor).unsqueeze(1)
    all_tensor_data_label = torch.from_numpy(gt_all).type(torch.FloatTensor)
    torch_dataset_all = Data.TensorDataset(all_tensor_data, all_tensor_data_label)

    all_iter = Data.DataLoader(
        dataset=torch_dataset_all,  # torch TensorDataset format
        batch_size=batch_size,  # mini batch size
        shuffle=False,
        num_workers=0,
    )
    return all_iter


def get_all_pixels(whole_data, model, PATCH_SIZE, device, batch_size=256):
    padded_data = np.lib.pad(whole_data, ((PATCH_SIZE, PATCH_SIZE), (PATCH_SIZE, PATCH_SIZE),
                                          (0, 0)), 'constant', constant_values=0)
    pred_all = []
    img_cols = whole_data.shape[1]
    img_rows = whole_data.shape[0]
    for i in tqdm(range(img_cols)):
        list_temp = sorted([i for i in range(img_rows*i, img_rows*(i+1))])
        iter_temp = generate_iter_all(img_rows, list_temp, whole_data, padded_data, PATCH_SIZE, batch_size)
        pred_ = []
        with torch.no_grad():
            for X, _ in iter_temp:
                X = X.to(device)
                model.eval()
                pred_.extend(np.array(model(X).cpu().argmax(axis=1)))
        pred_all.extend(pred_)

    return pred_all

